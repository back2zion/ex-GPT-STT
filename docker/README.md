# Docker ë°°í¬ ê°€ì´ë“œ

Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ Ex-GPT STTë¥¼ ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ³ êµ¬ì„± ìš”ì†Œ

### ì„œë¹„ìŠ¤
- **ex-gpt-stt**: ë©”ì¸ STT ì• í”Œë¦¬ì¼€ì´ì…˜
- **ollama**: AI íšŒì˜ë¡ ìƒì„±ìš© Qwen3-32B ëª¨ë¸ ì„œë²„

### ë³¼ë¥¨ ë§¤í•‘
- `./input`: ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬
- `./output`: ìƒì„±ëœ STT ê²°ê³¼ ë° íšŒì˜ë¡ ì €ì¥ ë””ë ‰í† ë¦¬
- `ollama_data`: Ollama ëª¨ë¸ ë°ì´í„° ì˜êµ¬ ì €ì¥

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ë””ë ‰í† ë¦¬ ì¤€ë¹„
```bash
cd docker/
mkdir -p input output
```

### 2. Docker Composeë¡œ ì‹¤í–‰
```bash
# GPU ì§€ì› í™˜ê²½ì—ì„œ ì‹¤í–‰
docker compose up -d

# CPUë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
DEVICE=cpu COMPUTE_TYPE=int8 docker compose up -d
```

### 3. Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec -it ex-gpt-stt-ollama ollama pull qwen3:32b
```

### 4. ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
```bash
# input ë””ë ‰í† ë¦¬ì— ì˜¤ë””ì˜¤ íŒŒì¼ ë³µì‚¬
cp /path/to/your/audio.mp3 input/

# ì²˜ë¦¬ ì‹œì‘ (ì¼íšŒì„±)
docker exec -it ex-gpt-stt-app python3 docker_infer.py

# ë˜ëŠ” ê°ì‹œ ëª¨ë“œë¡œ ì‹¤í–‰ (ìƒˆ íŒŒì¼ ìë™ ì²˜ë¦¬)
docker exec -e WATCH_MODE=true -it ex-gpt-stt-app python3 docker_infer.py
```

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜

### Whisper ì„¤ì •
- `WHISPER_MODEL`: ëª¨ë¸ í¬ê¸° (default: `large-v3`)
  - ì˜µì…˜: `tiny`, `base`, `small`, `medium`, `large-v3`
- `DEVICE`: ì²˜ë¦¬ ì¥ì¹˜ (default: `cuda`)
  - ì˜µì…˜: `cuda`, `cpu`
- `COMPUTE_TYPE`: ì—°ì‚° íƒ€ì… (default: `float16`)
  - GPU: `float16`, `int8`
  - CPU: `int8`, `float32`

### ì‹¤í–‰ ëª¨ë“œ
- `WATCH_MODE`: íŒŒì¼ ê°ì‹œ ëª¨ë“œ (default: `false`)
  - `true`: ìƒˆ íŒŒì¼ ìë™ ê°ì§€ ë° ì²˜ë¦¬
  - `false`: ì¼íšŒì„± ì²˜ë¦¬

### Ollama ì„¤ì •
- `OLLAMA_BASE_URL`: Ollama ì„œë²„ URL (default: `http://ollama:11434`)

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì‹¤í–‰
```bash
# ì»¨í…Œì´ë„ˆ ì‹œì‘
docker compose up -d

# ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ê°€
cp meeting.mp3 input/

# ì²˜ë¦¬ ì‹¤í–‰
docker exec -it ex-gpt-stt-app python3 docker_infer.py

# ê²°ê³¼ í™•ì¸
ls output/
# meeting_STT_20240315_143022.txt
# meeting_íšŒì˜ë¡_20240315_143022.md
```

### ê°ì‹œ ëª¨ë“œ (ìë™ ì²˜ë¦¬)
```bash
# ê°ì‹œ ëª¨ë“œë¡œ ì‹œì‘
docker exec -e WATCH_MODE=true -d ex-gpt-stt-app python3 docker_infer.py

# íŒŒì¼ ì¶”ê°€í•˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
cp new_audio.wav input/

# ë¡œê·¸ í™•ì¸
docker logs -f ex-gpt-stt-app
```

### CPU ì „ìš© ì‹¤í–‰
```bash
# CPU ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
DEVICE=cpu COMPUTE_TYPE=int8 docker compose up -d
```

## ğŸ”§ ì»¤ìŠ¤í…€ ì„¤ì •

### docker-compose.override.yml ìƒì„±
```yaml
version: '3.8'

services:
  ex-gpt-stt:
    environment:
      - WHISPER_MODEL=medium  # ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
      - WATCH_MODE=true       # ìë™ ê°ì‹œ ëª¨ë“œ
    volumes:
      - /your/custom/input:/app/input:ro
      - /your/custom/output:/app/output
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ìƒíƒœ
docker compose ps

# ë¡œê·¸ í™•ì¸
docker compose logs -f

# ê°œë³„ ì„œë¹„ìŠ¤ ë¡œê·¸
docker logs -f ex-gpt-stt-app
docker logs -f ex-gpt-stt-ollama
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
```bash
# CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
docker stats

# GPU ì‚¬ìš©ëŸ‰ (nvidia-smi í•„ìš”)
nvidia-smi
```

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### GPU ì¸ì‹ ì•ˆë¨
```bash
# NVIDIA Container Toolkit ì„¤ì¹˜ í™•ì¸
docker run --rm --gpus all nvidia/cuda:12.3.2-base-ubuntu22.04 nvidia-smi
```

### Ollama ì—°ê²° ì‹¤íŒ¨
```bash
# Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker exec ex-gpt-stt-ollama ollama list

# ìˆ˜ë™ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec -it ex-gpt-stt-ollama ollama pull qwen3:32b
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
WHISPER_MODEL=base docker compose up -d

# CPU ëª¨ë“œë¡œ ë³€ê²½
DEVICE=cpu COMPUTE_TYPE=int8 docker compose up -d
```

## ğŸ§¹ ì •ë¦¬

```bash
# ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ë° ì œê±°
docker compose down

# ë³¼ë¥¨ê¹Œì§€ ì™„ì „ ì‚­ì œ
docker compose down -v

# ì´ë¯¸ì§€ ì •ë¦¬
docker image prune -f
```