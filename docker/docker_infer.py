#!/usr/bin/env python3
"""
Dockerìš© STT ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
Korean STT with meeting minutes generation for containerized deployment
"""

import os
import sys
import time
import requests
from datetime import datetime
from pathlib import Path
from faster_whisper import WhisperModel

# í™˜ê²½ ë³€ìˆ˜
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
INPUT_DIR = Path("/app/input")
OUTPUT_DIR = Path("/app/output")
MODEL_SIZE = os.getenv("WHISPER_MODEL", "large-v3")
DEVICE = os.getenv("DEVICE", "cuda")
COMPUTE_TYPE = os.getenv("COMPUTE_TYPE", "float16")

def setup_directories():
    """ë””ë ‰í† ë¦¬ ì„¤ì •"""
    INPUT_DIR.mkdir(exist_ok=True)
    OUTPUT_DIR.mkdir(exist_ok=True)
    print(f"ğŸ“ Input directory: {INPUT_DIR}")
    print(f"ğŸ“ Output directory: {OUTPUT_DIR}")

def wait_for_ollama():
    """Ollama ì„œë¹„ìŠ¤ ëŒ€ê¸°"""
    print("ğŸ¤– Ollama ì„œë¹„ìŠ¤ ì—°ê²° ëŒ€ê¸° ì¤‘...")
    max_attempts = 30
    attempt = 0
    
    while attempt < max_attempts:
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
            if response.status_code == 200:
                print("âœ… Ollama ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ!")
                return True
        except requests.exceptions.RequestException:
            pass
        
        attempt += 1
        print(f"â³ Ollama ì—°ê²° ì‹œë„ {attempt}/{max_attempts}...")
        time.sleep(5)
    
    print("âŒ Ollama ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    return False

def initialize_whisper():
    """Whisper ëª¨ë¸ ì´ˆê¸°í™”"""
    print(f"ğŸ¤ Whisper {MODEL_SIZE} ëª¨ë¸ ë¡œë”© ì¤‘...")
    print(f"ğŸ”§ Device: {DEVICE}, Compute Type: {COMPUTE_TYPE}")
    
    try:
        model = WhisperModel(MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)
        print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        return model
    except Exception as e:
        print(f"âŒ Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        sys.exit(1)

def transcribe_audio(model, audio_file):
    """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬"""
    print(f"ğŸµ ì „ì‚¬ ì‹œì‘: {audio_file.name}")
    
    segments, info = model.transcribe(
        str(audio_file),
        beam_size=5,
        language="ko",
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=500),
        temperature=0.0,
        compression_ratio_threshold=2.4,
        no_speech_threshold=0.6,
        condition_on_previous_text=False,
        initial_prompt="í•œêµ­ì–´ íšŒì˜ ë‚´ìš©ì…ë‹ˆë‹¤."
    )
    
    # ì „ì‚¬ ê²°ê³¼ ìˆ˜ì§‘
    transcription = ""
    segment_list = []
    
    for segment in segments:
        transcription += segment.text.strip() + " "
        segment_list.append({
            'start': segment.start,
            'end': segment.end,
            'text': segment.text.strip()
        })
        print(f"[{segment.start:.1f}s] {segment.text.strip()}")
    
    return transcription.strip(), segment_list, info

def analyze_with_ai(transcription):
    """AIë¡œ íšŒì˜ ë‚´ìš© ë¶„ì„"""
    if not transcription:
        return create_simple_analysis()
    
    print("ğŸ¤– AI ë¶„ì„ ì‹œì‘...")
    
    prompt = f"""ë‹¤ìŒ íšŒì˜ ì „ì‚¬ ë‚´ìš©ì„ ë¶„ì„í•´ì„œ êµ¬ì¡°í™”ëœ íšŒì˜ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì „ì‚¬ ë‚´ìš©: {transcription}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. íšŒì˜ ì£¼ì œ: [ì£¼ìš” ë…¼ì˜ ì£¼ì œ]
2. ì£¼ìš” ë…¼ì˜ì‚¬í•­: [ë…¼ì˜ì‚¬í•­ë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ]
3. ê²°ì •ì‚¬í•­: [ê²°ì •ëœ ì‚¬í•­ë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ]
4. ì´ìŠˆ/ë¬¸ì œì : [ë°œê²¬ëœ ì´ìŠˆë“¤ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ]
5. í–¥í›„ ê³„íš: [ì•ìœ¼ë¡œì˜ ê³„íšì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ]

í•œêµ­ì–´ë¡œ êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    try:
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json={
                "model": "qwen3:32b",
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.3}
            },
            timeout=120
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result.get('response', '')
            print("âœ… AI ë¶„ì„ ì™„ë£Œ!")
            return parse_ai_response(ai_response)
        else:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: HTTP {response.status_code}")
            return create_simple_analysis()
            
    except Exception as e:
        print(f"âŒ AI ë¶„ì„ ì˜¤ë¥˜: {e}")
        return create_simple_analysis()

def parse_ai_response(ai_response):
    """AI ì‘ë‹µ íŒŒì‹±"""
    analysis = {
        'topic': 'í”„ë¡œì íŠ¸ ë…¼ì˜',
        'discussions': [],
        'decisions': [],
        'issues': [],
        'plans': []
    }
    
    lines = ai_response.split('\n')
    current_section = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        if 'íšŒì˜ ì£¼ì œ:' in line or 'ì£¼ì œ:' in line:
            analysis['topic'] = line.split(':', 1)[1].strip()
        elif 'ë…¼ì˜ì‚¬í•­:' in line or 'ë…¼ì˜' in line:
            current_section = 'discussions'
        elif 'ê²°ì •ì‚¬í•­:' in line or 'ê²°ì •' in line:
            current_section = 'decisions'
        elif 'ì´ìŠˆ' in line or 'ë¬¸ì œì ' in line:
            current_section = 'issues'
        elif 'í–¥í›„' in line or 'ê³„íš' in line:
            current_section = 'plans'
        elif line.startswith('- ') and current_section:
            analysis[current_section].append(line[2:].strip())
        elif line.startswith('â€¢ ') and current_section:
            analysis[current_section].append(line[2:].strip())
    
    return analysis

def create_simple_analysis():
    """ê°„ë‹¨í•œ ë¶„ì„ (AI ì‹¤íŒ¨ì‹œ ëŒ€ì²´)"""
    return {
        'topic': 'íšŒì˜ ë…¼ì˜ì‚¬í•­',
        'discussions': ['ì „ì‚¬ ë‚´ìš© ê¸°ë°˜ ë…¼ì˜ì‚¬í•­'],
        'decisions': ['ì£¼ìš” ê²°ì •ì‚¬í•­'],
        'issues': ['í™•ì¸ëœ ì´ìŠˆì‚¬í•­'],
        'plans': ['í–¥í›„ ì§„í–‰ ê³„íš']
    }

def save_results(audio_file, transcription, segments, analysis, info):
    """ê²°ê³¼ ì €ì¥"""
    base_name = audio_file.stem
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # STT ê²°ê³¼ ì €ì¥
    stt_file = OUTPUT_DIR / f"{base_name}_STT_{timestamp}.txt"
    with open(stt_file, 'w', encoding='utf-8') as f:
        f.write(f"{base_name} - STT ê²°ê³¼\n")
        f.write(f"ì²˜ë¦¬ì¼ì‹œ: {datetime.now().strftime('%Y.%m.%d %H:%M')}\n")
        f.write(f"íŒŒì¼ê¸¸ì´: {info.duration:.0f}ì´ˆ\n")
        f.write(f"ì–¸ì–´: {info.language} (í™•ë¥ : {info.language_probability:.1%})\n")
        f.write("=" * 50 + "\n\n")
        
        for segment in segments:
            f.write(f"[{segment['start']:.1f}s -> {segment['end']:.1f}s]\n")
            f.write(f"{segment['text']}\n\n")
    
    # íšŒì˜ë¡ ì €ì¥
    minutes_file = OUTPUT_DIR / f"{base_name}_íšŒì˜ë¡_{timestamp}.md"
    with open(minutes_file, 'w', encoding='utf-8') as f:
        f.write(f"# íšŒì˜ë¡ - {analysis['topic']}\n\n")
        f.write(f"**ì¼ì‹œ:** {datetime.now().strftime('%Y.%m.%d %H:%M')}\n")
        f.write(f"**íŒŒì¼:** {audio_file.name}\n")
        f.write(f"**ê¸¸ì´:** {info.duration:.1f}ì´ˆ\n\n")
        
        f.write("## ğŸ’¬ ì£¼ìš” ë…¼ì˜ì‚¬í•­\n")
        for item in analysis['discussions']:
            f.write(f"- {item}\n")
        f.write("\n")
        
        f.write("## âœ… ê²°ì •ì‚¬í•­\n")
        for item in analysis['decisions']:
            f.write(f"- {item}\n")
        f.write("\n")
        
        f.write("## âš ï¸ ì´ìŠˆì‚¬í•­\n")
        for item in analysis['issues']:
            f.write(f"- {item}\n")
        f.write("\n")
        
        f.write("## ğŸ“‹ í–¥í›„ ê³„íš\n")
        for item in analysis['plans']:
            f.write(f"- {item}\n")
        f.write("\n")
        
        f.write("---\n*AI ìŒì„±ì¸ì‹ìœ¼ë¡œ ìë™ ìƒì„±ëœ íšŒì˜ë¡ì…ë‹ˆë‹¤.*\n")
    
    print(f"ğŸ’¾ STT ê²°ê³¼ ì €ì¥: {stt_file.name}")
    print(f"ğŸ’¾ íšŒì˜ë¡ ì €ì¥: {minutes_file.name}")
    
    return stt_file, minutes_file

def process_audio_files():
    """ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ ì²˜ë¦¬"""
    supported_formats = ('.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg')
    audio_files = []
    
    for ext in supported_formats:
        audio_files.extend(INPUT_DIR.glob(f"*{ext}"))
    
    if not audio_files:
        print(f"âŒ {INPUT_DIR}ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì§€ì› í˜•ì‹: {', '.join(supported_formats)}")
        return
    
    print(f"ğŸµ {len(audio_files)}ê°œ ì˜¤ë””ì˜¤ íŒŒì¼ ë°œê²¬")
    
    # Whisper ëª¨ë¸ ì´ˆê¸°í™”
    model = initialize_whisper()
    
    for audio_file in audio_files:
        try:
            print(f"\n{'='*60}")
            print(f"ì²˜ë¦¬ ì¤‘: {audio_file.name}")
            
            # STT ì²˜ë¦¬
            transcription, segments, info = transcribe_audio(model, audio_file)
            
            # AI ë¶„ì„
            analysis = analyze_with_ai(transcription)
            
            # ê²°ê³¼ ì €ì¥
            save_results(audio_file, transcription, segments, analysis, info)
            
            print(f"âœ… {audio_file.name} ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ {audio_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Ex-GPT STT Docker ì»¨í…Œì´ë„ˆ ì‹œì‘")
    print("=" * 60)
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    setup_directories()
    
    # Ollama ì„œë¹„ìŠ¤ ëŒ€ê¸°
    if not wait_for_ollama():
        print("âš ï¸ Ollama ì—†ì´ STTë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    
    # ì§€ì†ì  ëª¨ë‹ˆí„°ë§ ëª¨ë“œ
    if os.getenv("WATCH_MODE", "false").lower() == "true":
        print("ğŸ‘ï¸ íŒŒì¼ ê°ì‹œ ëª¨ë“œ ì‹œì‘...")
        processed_files = set()
        
        while True:
            try:
                # ìƒˆ íŒŒì¼ í™•ì¸
                audio_files = []
                for ext in ('.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg'):
                    audio_files.extend(INPUT_DIR.glob(f"*{ext}"))
                
                new_files = [f for f in audio_files if f not in processed_files]
                
                if new_files:
                    print(f"ğŸ†• ìƒˆ íŒŒì¼ {len(new_files)}ê°œ ë°œê²¬!")
                    for audio_file in new_files:
                        # íŒŒì¼ ì²˜ë¦¬ ë¡œì§...
                        processed_files.add(audio_file)
                
                time.sleep(10)  # 10ì´ˆë§ˆë‹¤ í™•ì¸
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ íŒŒì¼ ê°ì‹œ ì¤‘ë‹¨")
                break
    else:
        # ì¼íšŒì„± ì²˜ë¦¬ ëª¨ë“œ
        process_audio_files()
        print("\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")

if __name__ == "__main__":
    main()